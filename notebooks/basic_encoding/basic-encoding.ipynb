{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tutorial - A Basic Encoding Script\n",
    "\n",
    "In this tutorial, you will learn how to create an encoding from scratch, using the Bitmovin APIs and the Python SDK that wraps them. We will explain the concepts and the terminology that we use.\n",
    "\n",
    "This tutorial concentrates on taking a single source file, encoding it into a ladder of multiple renditions, and creating a manifest which can be played back by any modern video player on most devices and browsers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GAS_K2t7O-Gl",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Understanding how the API is composed\n",
    "![object model](http://demo.bitmovin.com/public/learning-labs/encoding/ObjectModel_ABR.png)\n",
    "\n",
    "For a complete description of the Bitmovin data model, check our [Object Model documentation]( https://bitmovin.com/docs/encoding/tutorials/understanding-the-bitmovin-encoding-object-model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "qI4_K7g8bwFF",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A Little Setup\n",
    "Let's import the Bitmovin API Client into our python script, as well as other dependencies we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "colab": {},
    "colab_type": "code",
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "a5L_4anwbwFI"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../libs')\n",
    "\n",
    "import collections\n",
    "import os\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "from bitmovin_api_sdk import BitmovinApi, BitmovinApiLogger\n",
    "from bitmovin_api_sdk import HttpsInput, S3Output, AwsCloudRegion\n",
    "from bitmovin_api_sdk import StreamInput, StreamSelectionMode\n",
    "from bitmovin_api_sdk import ProfileH264\n",
    "from bitmovin_api_sdk import H264VideoConfiguration, PresetConfiguration\n",
    "from bitmovin_api_sdk import Encoding, CloudRegion\n",
    "from bitmovin_api_sdk import MuxingStream, Fmp4Muxing, EncodingOutput, AclEntry, AclPermission\n",
    "from bitmovin_api_sdk import Stream, Status\n",
    "from bitmovin_api_sdk import DashManifestDefault, DashManifestDefaultVersion\n",
    "from bitmovin_api_sdk import AacAudioConfiguration\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For the purpose of this tutorial, we also import a few additional helpers. You won't need these in your own scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "colab": {},
    "colab_type": "code",
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "a5L_4anwbwFI"
   },
   "outputs": [],
   "source": [
    "import config as cfg\n",
    "import helpers\n",
    "from IPython.display import display, IFrame\n",
    "from vdom import p, div, b, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are being quite specific about the Bitmovin objects that we want to import, just to make things clear for this example..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "JABsdDe4bwFN",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Secret sauce\n",
    "The API key is what you need to authenticate with the Bitmovin API. You can find it in the dashboard in the [Account section](https://bitmovin.com/dashboard/account)\n",
    "\n",
    "It is a __secret__, and should be treated as such. If someone else gets hold of your key, they can run encodings on your account (or your organisation accounts) and get information about previous ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "colab": {},
    "colab_type": "code",
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "rsOtBeuobwFQ"
   },
   "outputs": [],
   "source": [
    "cfg.API_KEY = os.getenv('API_KEY', \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Organization ID indicates what Bitmovin account you want to create and process your encodings in. Leave it empty if you are using your own account. If you belong to a multi-tenant organization, you need to get the organisation ID from the dashboard in the [Organization section](https://bitmovin.com/dashboard/organization/overview)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "colab": {},
    "colab_type": "code",
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "rsOtBeuobwFQ"
   },
   "outputs": [],
   "source": [
    "cfg.ORG_ID = os.getenv('ORG_ID', \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For this learning lab we have created an S3 bucket and a (very limited) user we can all use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "colab": {},
    "colab_type": "code",
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "rsOtBeuobwFQ"
   },
   "outputs": [],
   "source": [
    "cfg.S3_BUCKET_NAME = os.getenv('S3_BUCKET_NAME', \"\")\n",
    "cfg.S3_ACCESS_KEY = os.getenv('S3_ACCESS_KEY', \"\")\n",
    "cfg.S3_SECRET_KEY = os.getenv('S3_SECRET_KEY', \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to prevent conflicts between all our encodings, let's add something unique to each of us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "colab": {},
    "colab_type": "code",
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "rsOtBeuobwFQ"
   },
   "outputs": [],
   "source": [
    "cfg.MY_ID = os.getenv('MY_ID', \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We'll quickly run some checks to make sure that your setup is ready to use. This is where we use these helpers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "colab": {},
    "colab_type": "code",
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "rsOtBeuobwFQ"
   },
   "outputs": [],
   "source": [
    "msg = helpers.validate_config()\n",
    "base_output_path = helpers.build_output_path()\n",
    "\n",
    "display(\n",
    "    div(\n",
    "        p(f\"{msg}. Your output files will be added to subdirectory \", b(f\"{base_output_path}\")),\n",
    "        style={\"color\": \"green\"}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a production script, you won't need this (or rather, you'll need to do something that is suitable for your workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "bEYpTWuebwFN",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Configuring our Encoding\n",
    "Now that the boring bits are behind us, we are (finally) ready to start the real work.\n",
    "\n",
    "First, we need to instantiate the API client with our secrets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "colab": {},
    "colab_type": "code",
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "Ia50HGtDbwFS"
   },
   "outputs": [],
   "source": [
    "api = BitmovinApi(api_key=cfg.API_KEY,\n",
    "                  tenant_org_id=cfg.ORG_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "aOvDExJnbwFW",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"img/step1.svg\" alt=\"Input and Output\" width=\"320px\" align=\"right\"/>\n",
    "\n",
    "## Input and Output locations\n",
    "Every encoding needs at least one input and output. In Bitmovin parlance an `Input` is an input storage location with a specific transport protocol, for example an HTTPS location. It is _not_ a specific file. Our documentation provides a full list of [supported Inputs](https://bitmovin.com/docs/encoding/articles/supported-input-output-storages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "colab": {},
    "colab_type": "code",
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "CN1mU4UIbwFY"
   },
   "outputs": [],
   "source": [
    "input = HttpsInput(name=f'{cfg.MY_ID}_LearningLab_Sources',\n",
    "                   description='Web server for Bitmovin Dev Lab inputs',\n",
    "                   host=\"bitmovin-learning-labs-london.s3.amazonaws.com\")\n",
    "input = api.encoding.inputs.https.create(https_input=input)\n",
    "print(\"Created input '{}' with id: {}\".format(input.name, input.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we first create a resource in the SDK, and then submit it to the API for creation. The API will return a full representation of the object, and generated an ID for it. We will use those identifiers to link the various objects that make up the full configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AVLfJoJe_mp-",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The same concepts apply to the `Output`, which defines where we will store the resulting files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_9e_03we_iIu"
   },
   "outputs": [],
   "source": [
    "output = S3Output(name=f'{cfg.MY_ID}_{cfg.S3_BUCKET_NAME}',\n",
    "                  description='Bucket for Bitmovin Dev Lab outputs',\n",
    "                  bucket_name=cfg.S3_BUCKET_NAME,\n",
    "                  access_key=cfg.S3_ACCESS_KEY,\n",
    "                  secret_key=cfg.S3_SECRET_KEY)\n",
    "output = api.encoding.outputs.s3.create(s3_output=output)\n",
    "print(\"Created output '{}' with id: {}\".format(output.name, output.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note_: It is best practice to _reuse_ inputs and outputs you have created before, not create a new one every time. \n",
    "\n",
    "You can and should query the API to retrieve the resources you previously created inputs, by their name. The `name` and `description` properties can be added to all Bitmovin resources. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "7EwLTNPbbwFg",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"img/step2.svg\" alt=\"StreamInput\" width=\"320px\" align=\"right\"/>\n",
    "\n",
    "## Mapping input media streams\n",
    "We can now define what source file to use in the encoding. \n",
    "To do so, we need to create a `StreamInput` resource, which specifies on what _input_ our file is located (by using its ID), at what _path_. We also define what media track to select to decode (and later encode). \n",
    "\n",
    "The first input stream we specify is for the video track:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "colab": {},
    "colab_type": "code",
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "SGZB3N7nbwFh"
   },
   "outputs": [],
   "source": [
    "video_input_stream = StreamInput(input_id=input.id, \n",
    "                                 input_path=\"input-files/cosmos_laundromat.mp4\", \n",
    "                                 selection_mode=StreamSelectionMode.AUTO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "JYQcF_g_bwFl",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The next one we will create is for the audio. We've specified `StreamSelectionMode.AUDIO_RELATIVE` here and `position=0` to indicate I want the first (0th) audio track in numerical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "colab": {},
    "colab_type": "code",
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "7fMdtxjzbwFm"
   },
   "outputs": [],
   "source": [
    "audio_input_stream = StreamInput(input_id=input.id, \n",
    "                                 input_path='input-files/cosmos_laundromat.mp4', \n",
    "                                 selection_mode=StreamSelectionMode.AUDIO_RELATIVE, \n",
    "                                 position=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "fxVXZWFxbwFq"
   },
   "source": [
    "Note that the `StreamInput` is not a resource that is submitted to the API directly. It is an internal object used within the SDK, which is used later in the definition of other resources. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "Q_dldXfbbwFr",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"img/step3.svg\" alt=\"Configuration\" width=\"320px\" align=\"right\"/>\n",
    "\n",
    "## Configuring the codecs\n",
    "\n",
    "Next we need to create the codec configurations that define how those files get encoded into the output streams.\n",
    "\n",
    "We use a helper tuple (a Python-esque construct) to group up our desired output height, bitrate, and video profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "colab": {},
    "colab_type": "code",
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "gzXbDCHFbwFs"
   },
   "outputs": [],
   "source": [
    "MyProfile=collections.namedtuple('MyProfile', 'height bitrate profile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Ladder\n",
    "\n",
    "We then define a \"ladder\" as a set of encoding configurations for the encoder to generate. We will be using H264/AVC in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "colab": {},
    "colab_type": "code",
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "gzXbDCHFbwFs"
   },
   "outputs": [],
   "source": [
    "video_profiles = [\n",
    "    MyProfile(height=240,  bitrate=400_000,   profile=ProfileH264.MAIN),\n",
    "    MyProfile(height=360,  bitrate=800_000,   profile=ProfileH264.HIGH),\n",
    "    MyProfile(height=480,  bitrate=1_200_000, profile=ProfileH264.HIGH),\n",
    "    MyProfile(height=720,  bitrate=2_400_000, profile=ProfileH264.HIGH),\n",
    "    MyProfile(height=1080, bitrate=4_800_000, profile=ProfileH264.HIGH),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "RZpJJB0kbwFw",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Video\n",
    "\n",
    "We can now create each of these video profiles. We will use one of the [preset configurations](https://bitmovin.com/docs/encoding/tutorials/h264-presets), which are templates defined for most common use cases, whether your focus is on performance or quality, and they should always be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "colab": {},
    "colab_type": "code",
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "9QaSJ2e0bwFy"
   },
   "outputs": [],
   "source": [
    "video_configs = []\n",
    "for profile in video_profiles:\n",
    "    video_config = H264VideoConfiguration(\n",
    "        name=f\"{cfg.MY_ID}_H264-{profile.height}p@{profile.bitrate}\",\n",
    "        height=profile.height, \n",
    "        bitrate=profile.bitrate, \n",
    "        profile=profile.profile,\n",
    "        preset_configuration=PresetConfiguration.VOD_STANDARD\n",
    "    )\n",
    "    video_config = api.encoding.configurations.video.h264.create(video_config)\n",
    "    video_configs.append(video_config)\n",
    "    print(\"Created video codec config '{}' with id: {}\".format(video_config.name, video_config.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that just like inputs and outputs, these resources can and should also be re-used. You can also create them in the dashboard if desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "nbHDVU1xbwF4",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Adaptive bitrate video\n",
    "\n",
    "Let's pause for a second and cover _why_ we are generating multiple profiles here. \n",
    "\n",
    "We are encoding our source video in such a way that it can be played back in a player that supports Adaptive Bitrate (ABR) Streaming. With this mechanism, the Video Player can choose which representation (often called rendition) to play, based on its available bandwidth and capabilities, and can also switch between them dynamically, going to a higher bitrate (and therefore better quality) as the available bandwidth increases, or going to lower bitrates (and lower qualities) as the network conditions deteriorate. \n",
    "\n",
    "Each of these representations is a separate encode of the source files, and thus requires a distinct configuration of the encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "T006y4X1bwF6",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Audio\n",
    "We also need to create the audio configuration. A single AAC stream will do for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "colab": {},
    "colab_type": "code",
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "sJCH8XmCbwF7"
   },
   "outputs": [],
   "source": [
    "audio_config = AacAudioConfiguration(\n",
    "    name=f\"{cfg.MY_ID}_AAC-128k\",\n",
    "    bitrate=128_000, \n",
    "    rate=48_000.0)\n",
    "audio_config = api.encoding.configurations.audio.aac.create(aac_audio_configuration=audio_config)\n",
    "print(\"Created audio codec config '{}' with id: {}\".format(audio_config.name, audio_config.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kif4n-VExk8v",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Encoding itself\n",
    "\n",
    "<img src=\"img/step4.svg\" alt=\"Encoding\" width=\"320px\" align=\"right\"/>\n",
    "\n",
    "Each encoding job will have a resource that defines it. We define a number of aspects of the encoding through it:\n",
    "- The `CloudRegion` defines through what cloud provider and in which region to perform the encoding. We are setting it to `AUTO` here, which means that Bitmovin will attempt to make a \"sensible\" choice about where to run the encoding. It's best to use a specific region however.\n",
    "\n",
    "- The `EncoderVersion`: You should set it to `STABLE` to ensure you get the most up to date version of the encoder, for best performance and reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "colab": {},
    "colab_type": "code",
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "KrRz_lEibwGA",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "encoding = Encoding(name=f\"{cfg.MY_ID} - basic encoding tutorial\",\n",
    "                    encoder_version=\"STABLE\",\n",
    "                    cloud_region=CloudRegion.AUTO)\n",
    "encoding = api.encoding.encodings.create(encoding=encoding)\n",
    "print(\"Created encoding '{}' with id: {}\".format(encoding.name, encoding.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "IJHCBK8cbwGG",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mapping inputs to outputs\n",
    "\n",
    "<img src=\"img/step4b.svg\" alt=\"Intermediary Summary\" width=\"320px\" align=\"right\"/>\n",
    "\n",
    "So far we have created:\n",
    "* An input\n",
    "* An output\n",
    "* A set of video and audio \"profiles\"\n",
    "* An empty encoding object\n",
    "\n",
    "Having all these \"non-dependent\" objects ready, it's now time to connect the chain that will tie in input and output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MBwiR1VozvNy",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Streams\n",
    "\n",
    "<img src=\"img/step5.svg\" alt=\"Streams\" width=\"320px\" align=\"right\"/>\n",
    "\n",
    "We will first create a series of output streams. These simply map one or multiple _input_ streams to a single (elementary) _output_ stream, and are the raw output of the encoding process itself.\n",
    "\n",
    "For our ABR tutorial use case, there is a simple one-to-one relationship between codecs and video streams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So, for each config, we create a corresponding `Stream`, which we link to the `StreamInput` created earlier. We link the Stream to a `Configuration`, and attach it to our `Encoding`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "colab": {},
    "colab_type": "code",
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "CbC2W9A7bwGI",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "video_streams = []\n",
    "for config in video_configs:\n",
    "    stream_shortname = '{}p_{}k'.format(config.height, round(config.bitrate/1000))\n",
    "    video_stream = Stream(name=f\"{cfg.MY_ID}_{stream_shortname}\",\n",
    "                          description=stream_shortname,\n",
    "                          codec_config_id=config.id,\n",
    "                          input_streams=[video_input_stream])\n",
    "    video_stream = api.encoding.encodings.streams.create(encoding.id, stream=video_stream)\n",
    "    video_streams.append(video_stream)\n",
    "    print(\"Created video stream '{}' with id: {}\".format(video_stream.name, video_stream.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And then we do the same thing for the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "colab": {},
    "colab_type": "code",
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "CbC2W9A7bwGI",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "audio_stream = Stream(name=f'{cfg.MY_ID}_AAC',\n",
    "                      codec_config_id=audio_config.id, \n",
    "                      input_streams=[audio_input_stream])\n",
    "audio_stream = api.encoding.encodings.streams.create(encoding.id, stream=audio_stream)\n",
    "print(\"Created audio stream '{}' with id: {}\".format(audio_stream.name, audio_stream.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "zhh-YrldbwGS",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Muxing\n",
    "\n",
    "<img src=\"img/step6.svg\" alt=\"Muxings\" width=\"320px\" align=\"right\"/>\n",
    "\n",
    "Raw output isn't enough however. An output stream must be _muxed_ into a container, for example an MPEG Transport Stream, or fragmented MPEG 4 boxes (ISOBMFF). \n",
    "\n",
    "For each item we need to add our stream to a `MuxingStream`, which takes a stream, an `EncodingOutput` which specifies the output and the _path_ for this muxing and then create the `Muxing` itself. \n",
    "\n",
    "Note that muxings may contain multiple streams, and be replicated to multiple outputs. For simplicity's sake here, and in line with standard ABR practices, we create a separate muxing for each generated track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "colab": {},
    "colab_type": "code",
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "W_rG1d4QbwGT",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "video_muxings = []\n",
    "for video_stream in video_streams:\n",
    "    muxing_stream = MuxingStream(stream_id=video_stream.id)\n",
    "    muxing_output = EncodingOutput(output_id=output.id,\n",
    "                                   output_path='{}/video/{}'.format(base_output_path, video_stream.description),\n",
    "                                   acl=[AclEntry(permission=AclPermission.PUBLIC_READ)])\n",
    "    video_muxing = Fmp4Muxing(name=video_stream.name + \"_fmp4\",\n",
    "                              streams=[muxing_stream],\n",
    "                              segment_length=4.0,\n",
    "                              segment_naming=\"seg_%number%.m4s\",\n",
    "                              init_segment_name='init.mp4',\n",
    "                              outputs=[muxing_output])\n",
    "    video_muxing = api.encoding.encodings.muxings.fmp4.create(encoding_id=encoding.id, fmp4_muxing=video_muxing)\n",
    "    video_muxings.append(video_muxing)\n",
    "    print(\"Created video muxing '{}' with id: {}\".format(video_muxing.name, video_muxing.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "L1boUHUnbwGd",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We also create a separate audio muxing, into a separate folder. We could mux the audio with our video streams, but standard practice with ABR is to have separate audio-only muxings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5yEVXssZ1Erz"
   },
   "outputs": [],
   "source": [
    "audio_muxing_stream = MuxingStream(stream_id=audio_stream.id)\n",
    "audio_muxing_output = EncodingOutput(output_id=output.id,\n",
    "                                     output_path=base_output_path+'/audio/',\n",
    "                                     acl=[AclEntry(scope='*', permission=AclPermission.PUBLIC_READ)])\n",
    "audio_muxing = Fmp4Muxing(name=f\"{audio_stream.name}_fmp4\",\n",
    "                          streams=[audio_muxing_stream],\n",
    "                          segment_length=4.0,\n",
    "                          segment_naming=\"seg_%number%.m4s\",\n",
    "                          init_segment_name='init.mp4',\n",
    "                          outputs=[audio_muxing_output])\n",
    "audio_muxing = api.encoding.encodings.muxings.fmp4.create(encoding_id=encoding.id, fmp4_muxing=audio_muxing)\n",
    "print(\"Created audio muxing '{}' with id: {}\".format(audio_muxing.name, audio_muxing.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "XKj5Qq1ObwGg",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"img/step7.svg\" alt=\"Start\" width=\"320px\" align=\"right\"/>\n",
    "\n",
    "## Starting the encoding...\n",
    "\n",
    "Next we are going to start the encode! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "colab": {},
    "colab_type": "code",
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "FkiX8-1abwGi"
   },
   "outputs": [],
   "source": [
    "api.encoding.encodings.start(encoding.id)\n",
    "print(\"Starting encoding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "colab": {},
    "colab_type": "code",
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "FkiX8-1abwGi"
   },
   "outputs": [],
   "source": [
    "url = helpers.build_dashboard_url(encoding.id)\n",
    "display(\n",
    "    p(\"You can now check encoding progress in the dashboard at \", \n",
    "      a(f\"{url}\", href=f\"{url}\", target=\"_new\")\n",
    "    )\n",
    ")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tSJ5z8fsArjZ",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"img/step8.svg\" alt=\"Monitoring\" width=\"320px\" align=\"right\"/>\n",
    "\n",
    "### ... and monitoring it\n",
    "\n",
    "You can monitor the encoding in your script by polling its status on a regular basis. This is the easiest way to keep track of the encoding when you are testing your encoding configuration.\n",
    "\n",
    "For production environments however, you should use [webhooks](//https://bitmovin.com/docs/encoding/api-reference/sections/notifications-webhooks) instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yGno_QyOPs-X"
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    task = api.encoding.encodings.status(encoding.id)\n",
    "    print(\"Got task status {} - {}%\".format(task.status, task.progress))\n",
    "    if task.status == Status.ERROR:\n",
    "        print(\"Error during encoding!\")\n",
    "        raise SystemExit\n",
    "    if task.status == Status.FINISHED:\n",
    "        print(\"Encoding complete\")\n",
    "        break\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "x9FiZEwhbwGm",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Combining into a manifest\n",
    "\n",
    "<img src=\"img/step9.svg\" alt=\"Manifest\" width=\"320px\" align=\"right\"/>\n",
    "\n",
    "We will ask the encoder to generate the `Manifest` as well. The manifest is used by ABR players to find all information about quality levels, audio tracks, subtitles etc. \n",
    "\n",
    "We are going to generate a _DASH_ (Dynamic Adaptive Streaming over HTTP) manifest, which can be played on Android and iOS devices, as well as the Bitmovin player on most platforms.\n",
    "\n",
    "Bitmovin provides you with full flexibility to create manifests in a fine grained way. But we will be using `DefaultManifest` functionality, which will apply smart defaults to create a standard manifest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "colab": {},
    "colab_type": "code",
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "ODmU9M8ubwGo",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Creating manifests\")\n",
    "manifest_output = EncodingOutput(output_id=output.id,\n",
    "                                 output_path=base_output_path+'/',\n",
    "                                 acl=[AclEntry(scope='*', permission=AclPermission.PUBLIC_READ)])\n",
    "dash_manifest = DashManifestDefault(\n",
    "    name=f\"{cfg.MY_ID}_DashManifest\",\n",
    "    manifest_name=\"stream.mpd\",\n",
    "    encoding_id=encoding.id,\n",
    "    version=DashManifestDefaultVersion.V1,\n",
    "    outputs=[manifest_output])\n",
    "\n",
    "dash_manifest = api.encoding.manifests.dash.default.create(dash_manifest)\n",
    "print(\"Created manifest '{}' with id: {}\".format(dash_manifest.name, dash_manifest.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SwdEfdOQBbNH",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And now we can trigger the generation of the manifest... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ymo3a4wzBXwN"
   },
   "outputs": [],
   "source": [
    "api.encoding.manifests.dash.start(dash_manifest.id)\n",
    "print(\"Generating manifest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "... and monitor it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ymo3a4wzBXwN"
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    time.sleep(5)\n",
    "    status = api.encoding.manifests.dash.status(dash_manifest.id).status\n",
    "    if status == Status.FINISHED:\n",
    "        break\n",
    "    if status == Status.ERROR:\n",
    "        print(\"Error during dash manifest generation\")\n",
    "        raise SystemExit\n",
    "\n",
    "manifest_url = \"https://\"+cfg.S3_BUCKET_NAME+\".s3.amazonaws.com/\" + manifest_output.output_path + dash_manifest.manifest_name\n",
    "display( p(f\"Manifest URL: \", b(f\"{manifest_url}\")) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yn1wYl-QNCsk",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Playback test\n",
    "You can now try playing back the stream, by using the manifest URL in our test player at https://bitmovin.com/demos/stream-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LhKZhLfBSLav",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## In your own player\n",
    "Alternatively, you can just play it right here. \n",
    "You may have to whitelist the \"google.com\" domain for your player license first.\n",
    "\n",
    "To retrieve your license and add the domain, head to the Dashboard at https://bitmovin.com/dashboard/player/licenses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r7TDrikdS6qF"
   },
   "outputs": [],
   "source": [
    "cfg.PLAYER_LICENSE='f9e2cf25-9cdd-4c9d-a314-90fdb6d5590c'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r7TDrikdS6qF",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "embed_url = \"https://demo.bitmovin.com/public/learning-labs/encoding/test-players/basic-dash-player.html?\"\n",
    "embed_url += \"license=\"+cfg.PLAYER_LICENSE\n",
    "embed_url += \"&mpdurl=\"+manifest_url\n",
    "\n",
    "IFrame(src=embed_url, width=800, height=450)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
